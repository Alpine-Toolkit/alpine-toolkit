#! /usr/bin/env python3
# -*- Python -*-

# type class::
# type * &

####################################################################################################

import argparse
import os

import pygments
from pygments.lexers.c_cpp import CppLexer
from pygments.token import Token

####################################################################################################

argument_parser = argparse.ArgumentParser(description='Cpp Tokenizer')
argument_parser.add_argument('source_path', metavar='SOURCE',
                             help='c++ source')

args = argument_parser.parse_args()

####################################################################################################

class Name:

    ##############################################

    def __init__(self, token_type, name):

        self.token_type = token_type
        self.name = name
        self.new_name = self.rebless()

    ##############################################

    def rebless(self):

        if self.token_type is Token.Name.Class:
            return self.name
        if self.name.startswith('Q') or self.name.isupper():
            return self.name
        else:
            new_name = ""
            for i, c in enumerate(self.name):
                if i > 0 and ord('A') <= ord(c) <= ord('Z'):
                    new_name += '_' + c.lower()
                else:
                    new_name += c
            if self.name.endswith('Changed'):
                new_name = new_name[:-len('_changed')] + 'Changed'
            return new_name

####################################################################################################

with open(args.source_path, 'r') as f:
    source_code = f.read()

i = 0
while True:
    backup_path = args.source_path + '~{}~'.format(i)
    if os.path.exists(backup_path):
        i += 1
    else:
        break
print(backup_path)

with open(backup_path, 'w') as f:
    f.write(source_code)

new_source_code = ""
names = {}
for token_type, token in pygments.lex(source_code, CppLexer()):
    # print(token_type, token)
    if token_type in (Token.Name, Token.Name.Class, Token.Name.Function):
        if token not in names:
            names[token] = Name(token_type, token)
        new_source_code += names[token].new_name
    else:
        new_source_code += token

with open(args.source_path, 'w') as f:
    f.write(new_source_code)

# print(new_source_code)

# for name in sorted(names.keys()):
#     print(name, '->', names[name].new_name)
